{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2021 Semester 1\n",
    "\n",
    "## Assignment 2: Duration Classification with Recipe Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student ID(s): 1004503, 1005418"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 1,
=======
   "execution_count": 36,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
<<<<<<< Updated upstream
    "from collections import defaultdict\n",
=======
    "#import pickle\n",
    "import scipy\n",
    "#from xgboost import XGBClassifier\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
>>>>>>> Stashed changes
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "#testing"
   ]
  },
  {
<<<<<<< Updated upstream
   "cell_type": "code",
   "execution_count": null,
=======
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process for count vectorizer and doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all the required data and feature files\n",
    "\n",
<<<<<<< Updated upstream
    "recipe_train = pd.read_csv(\"ML2_Data/recipe_train.csv\")\n",
    "recipe_test = pd.read_csv(\"ML2_Data/recipe_train.csv\")\n",
=======
    "count_vec_name = scipy.sparse.load_npz(\"ML2_data/recipe_text_features_countvec/train_name_vec.npz\").toarray()\n",
    "count_vec_steps = scipy.sparse.load_npz(\"ML2_data/recipe_text_features_countvec/train_steps_vec.npz\").toarray()\n",
    "count_vec_ingr = scipy.sparse.load_npz(\"ML2_data/recipe_text_features_countvec/train_ingr_vec.npz\").toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2vec process\n",
>>>>>>> Stashed changes
    "\n",
    "train_name_bow = np.load(\"ML2_Data/recipe_text_features_countvec/\")\n",
    "test_name_bow = np.load(\"ML2_Data/recipe_test_features_countvec\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 39,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should prepare the data by reading it from a file and converting it into a useful format for training and testing\n",
    "\n",
<<<<<<< Updated upstream
    "def preprocess():\n",
    "    return"
=======
    "n_ingr = csv_data.iloc[:,2]\n",
    "n_ingr = n_ingr.values\n",
    "\n",
    "duration_array = csv_data.iloc[:,-1]\n",
    "duration_array = duration_array.values\n",
    "\n",
    "n_steps_array = []\n",
    "n_ingr_array = []\n",
    "for i in range(len(n_steps)):\n",
    "    n_steps_array.append([n_steps[i]])\n",
    "    n_ingr_array.append([n_ingr[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.hstack([n_steps_array, n_ingr_array, doc2vec100_steps, count_vec_name, count_vec_ingr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, duration_array, test_size=0.25, random_state=42, stratify=duration_array)"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train():\n",
    "    return"
=======
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del count_vec_name\n",
    "del count_vec_steps\n",
    "del count_vec_ingr\n",
    "del doc2vec100_name \n",
    "del doc2vec100_steps\n",
    "del doc2vec100_ingr \n",
    "del n_steps\n",
    "del n_ingr\n",
    "del duration_array\n",
    "del n_steps_array \n",
    "del n_ingr_array\n",
    "\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select k-best features\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=500)\n",
    "kbest.fit(X_train, y_train)\n",
    "X_train = kbest.transform(X_train)\n",
    "X_test = kbest.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy:  0.7864\n",
      "Time elapsed:  21.77417540550232\n",
      "0-R accuracy:  0.5062\n",
      "Time elapsed:  0.002000093460083008\n",
      "Logistic Regression accuracy:  0.7987\n",
      "Time elapsed:  2.427544355392456\n",
      "GNB accuracy:  0.6946\n",
      "Time elapsed:  0.3120710849761963\n",
      "Decision Tree accuracy:  0.716\n",
      "Time elapsed:  8.770989656448364\n",
      "Linear SVC accuracy:  0.7989\n",
      "Time elapsed:  39.292195558547974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import svm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import time\n",
    "\n",
    "#try different classifiers and evaluate individual model performance\n",
    "#code adapated from Practical 8\n",
    "\n",
    "models = [RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "          DummyClassifier(strategy='most_frequent'),\n",
    "          LogisticRegression(random_state=42),\n",
    "          GaussianNB(),\n",
    "          DecisionTreeClassifier(random_state=42),\n",
    "          svm.LinearSVC(random_state=42)]\n",
    "\n",
    "titles = ['Random Forest',\n",
    "          '0-R',\n",
    "          'Logistic Regression',\n",
    "          'GNB',\n",
    "          'Decision Tree',\n",
    "         'Linear SVC']\n",
    "\n",
    "# for title, model in zip(titles, models):\n",
    "    \n",
    "#     output = []\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_predict = model.predict(X_test)\n",
    "    \n",
    "#     for i in range(len(y_predict)):\n",
    "#         row = [i+1, y_predict[i]]\n",
    "#         output.append(row)\n",
    "    \n",
    "    \n",
    "#      output = pd.DataFrame(output, columns = ['id', 'duration_label'])\n",
    "#      output.to_csv(title + '_CV.csv', index = False)\n",
    "\n",
    "for model, title in zip(models, titles):\n",
    "    \n",
    "    t_start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    print(title, \"accuracy: \", model.score(X_test, y_test))\n",
    "    t_end = time.time()\n",
    "\n",
    "    print(\"Time elapsed: \", t_end - t_start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost algo\n",
    "t_start = time.time()\n",
    "xgb = XGBClassifier(random_state=0, tree_method='gpu_hist').fit(X_train, y_train)\n",
    "print(\"XGB accuracy: \", xgb.score(X_test, y_test))\n",
    "t_end = time.time()\n",
    "print(\"Time elapsed: \", t_end - t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rf', RandomForestClassifier(random_state=42)), ('lr', LogisticRegression(random_state=42)), ('gnb', GaussianNB())]\n"
     ]
    }
   ],
   "source": [
    "#choose classifiers for stacking algo\n",
    "classifiers = [RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "          LogisticRegression(random_state=42),\n",
    "          GaussianNB()]\n",
    "\n",
    "class_titles = ['rf',\n",
    "               'lr',\n",
    "               'gnb']\n",
    "\n",
    "print(list(zip(class_titles, classifiers)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacker accuracy: 0.8029\n",
      "Time elapsed: 113.34583854675293\n"
     ]
    }
   ],
   "source": [
    "#use stacking classifier\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "t_start = time.time()\n",
    "clf = StackingClassifier(estimators = list(zip(class_titles, classifiers)))\n",
    "score = clf.fit(X_train, y_train).score(X_test, y_test)\n",
    "t_end = time.time()\n",
    "\n",
    "print(\"Stacker accuracy:\", score)\n",
    "print(\"Time elapsed:\", t_end-t_start)"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
<<<<<<< Updated upstream
=======
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Havent refactored under here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "\n",
    "def predict():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< Updated upstream
    "\n",
    "def evaluate():\n",
    "    return"
=======
    "#initialise a meta classifier with Logistic Regression as the meta classifier\n",
    "\n",
    "classifiers = [LogisticRegression(random_state=42),\n",
    "          GaussianNB(random_state=42),\n",
    "          MultinomialNB(random_state=42),\n",
    "          DecisionTreeClassifier(random_state=42),\n",
    "          KNeighborsClassifier(random_state=42)]\n",
    "\n",
    "meta_clf_lr = LogisticRegression()\n",
    "stacker_lr = StackingClassifier(classifiers, meta_clf_lr)\n",
    "\n",
    "#create stacked model output\n",
    "output = []\n",
    "stacker_lr.fit(Xtrain, y_train)\n",
    "y_predict = stacker_lr.predict(Xtest)\n",
    "    \n",
    "for i in range(len(y_predict)):\n",
    "    row = [i+1, y_predict[i]]\n",
    "    output.append(row)\n",
    "    \n",
    "output = pd.DataFrame(output, columns = ['id', 'duration_label'])\n",
    "output.to_csv('stacker' + '_CV.csv', index = False)\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))"
>>>>>>> Stashed changes
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
