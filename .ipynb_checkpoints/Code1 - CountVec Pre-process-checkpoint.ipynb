{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2021 Semester 1\n",
    "\n",
    "## Assignment 2: Duration Classification with Recipe Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student ID(s): 1004503, 1005418"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 1,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
<<<<<<< Updated upstream
    "from collections import defaultdict\n",
=======
    "#import pickle\n",
    "import scipy\n",
    "#from xgboost import XGBClassifier\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
>>>>>>> Stashed changes
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
<<<<<<< Updated upstream
=======
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process for count vectorizer and doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "# Count Vectoriser process\n",
    "\n",
<<<<<<< Updated upstream
    "recipe_train = pd.read_csv(\"ML2_Data/recipe_train.csv\")\n",
    "recipe_test = pd.read_csv(\"ML2_Data/recipe_train.csv\")\n",
=======
    "count_vec_name = scipy.sparse.load_npz(\"ML2_data/recipe_text_features_countvec/train_name_vec.npz\").toarray()\n",
    "count_vec_steps = scipy.sparse.load_npz(\"ML2_data/recipe_text_features_countvec/train_steps_vec.npz\").toarray()\n",
    "count_vec_ingr = scipy.sparse.load_npz(\"ML2_data/recipe_text_features_countvec/train_ingr_vec.npz\").toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2vec process\n",
>>>>>>> Stashed changes
    "\n",
    "doc2vec100_name = pd.read_csv(\"ML2_data/recipe_text_features_doc2vec100/train_name_doc2vec100.csv\", header = None).values\n",
    "doc2vec100_steps = pd.read_csv(\"ML2_data/recipe_text_features_doc2vec100/train_steps_doc2vec100.csv\", header = None).values\n",
    "doc2vec100_ingr = pd.read_csv(\"ML2_data/recipe_text_features_doc2vec100/train_ingr_doc2vec100.csv\", header = None).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data from recipe csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate duration label\n",
    "csv_data = pd.read_csv(\"ML2_data/recipe_train.csv\")\n",
    "\n",
    "n_steps = csv_data.iloc[:,1]\n",
    "n_steps = n_steps.values\n",
    "\n",
<<<<<<< Updated upstream
    "def preprocess():\n",
    "    return"
=======
    "n_ingr = csv_data.iloc[:,2]\n",
    "n_ingr = n_ingr.values\n",
    "\n",
    "duration_array = csv_data.iloc[:,-1]\n",
    "duration_array = duration_array.values\n",
    "\n",
    "n_steps_array = []\n",
    "n_ingr_array = []\n",
    "for i in range(len(n_steps)):\n",
    "    n_steps_array.append([n_steps[i]])\n",
    "    n_ingr_array.append([n_ingr[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.hstack([n_steps_array, n_ingr_array,doc2vec100_ingr, doc2vec100_name, doc2vec100_steps,count_vec_steps, count_vec_name, count_vec_ingr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, duration_array, test_size=0.25, random_state=42, stratify=duration_array)"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< Updated upstream
    "\n",
    "def train():\n",
    "    return"
=======
    "import gc\n",
    "\n",
    "del count_vec_name\n",
    "del count_vec_steps\n",
    "del count_vec_ingr\n",
    "del doc2vec100_name \n",
    "del doc2vec100_steps\n",
    "del doc2vec100_ingr \n",
    "del n_steps\n",
    "del n_ingr\n",
    "del n_steps_array \n",
    "del n_ingr_array\n",
    "\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select k-best features\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=1000)\n",
    "kbest.fit(X_train, y_train)\n",
    "X_train = kbest.transform(X_train)\n",
    "X_test = kbest.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import svm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import time\n",
    "\n",
    "#try different classifiers and evaluate individual model performance\n",
    "#code adapated from Practical 8\n",
    "\n",
    "models = [RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "          DummyClassifier(strategy='most_frequent'),\n",
    "          LogisticRegression(random_state=42),\n",
    "          GaussianNB(),\n",
    "          DecisionTreeClassifier(random_state=42),\n",
    "          svm.LinearSVC(random_state=42)]\n",
    "\n",
    "titles = ['Random Forest',\n",
    "          '0-R',\n",
    "          'Logistic Regression',\n",
    "          'GNB',\n",
    "          'Decision Tree',\n",
    "         'Linear SVC']\n",
    "\n",
    "# for title, model in zip(titles, models):\n",
    "    \n",
    "#     output = []\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_predict = model.predict(X_test)\n",
    "    \n",
    "#     for i in range(len(y_predict)):\n",
    "#         row = [i+1, y_predict[i]]\n",
    "#         output.append(row)\n",
    "    \n",
    "    \n",
    "#      output = pd.DataFrame(output, columns = ['id', 'duration_label'])\n",
    "#      output.to_csv(title + '_CV.csv', index = False)\n",
    "\n",
    "for model, title in zip(models, titles):\n",
    "    \n",
    "    t_start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    print(title, \"accuracy: \", model.score(X_test, y_test))\n",
    "    t_end = time.time()\n",
    "\n",
    "    print(\"Time elapsed: \", t_end - t_start)\n",
    "\n"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< Updated upstream
    "\n",
    "def predict():\n",
    "    return"
=======
    "#XGBoost algo\n",
    "t_start = time.time()\n",
    "xgb = XGBClassifier(random_state=0, tree_method='gpu_hist').fit(X_train, y_train)\n",
    "print(\"XGB accuracy: \", xgb.score(X_test, y_test))\n",
    "t_end = time.time()\n",
    "print(\"Time elapsed: \", t_end - t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose classifiers for stacking algo\n",
    "classifiers = [RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "          LogisticRegression(random_state=42),\n",
    "          svm.LinearSVC(random_state=42)]\n",
    "\n",
    "class_titles = ['rf',\n",
    "               'lr',\n",
    "               'svc']\n",
    "\n",
    "print(list(zip(class_titles, classifiers)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use stacking classifier\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "t_start = time.time()\n",
    "clf = StackingClassifier(estimators = list(zip(class_titles, classifiers)))\n",
    "score = clf.fit(X_train, y_train).score(X_test, y_test)\n",
    "t_end = time.time()\n",
    "\n",
    "print(\"Stacker accuracy:\", score)\n",
    "print(\"Time elapsed:\", t_end-t_start)"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
<<<<<<< Updated upstream
   "source": [
    "\n",
    "def evaluate():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
>>>>>>> Stashed changes
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
