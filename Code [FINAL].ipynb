{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2021 Semester 1\n",
    "\n",
    "## Assignment 2: Duration Classification with Recipe Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student ID(s): 1004503, 1005418"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "#import pickle\n",
    "import scipy\n",
    "#from xgboost import XGBClassifier\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process for count vectorizer and doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectoriser process\n",
    "\n",
    "count_vec_name = scipy.sparse.load_npz(\"ML2_data/recipe_text_features_countvec/train_name_vec.npz\").toarray()\n",
    "count_vec_steps = scipy.sparse.load_npz(\"ML2_data/recipe_text_features_countvec/train_steps_vec.npz\").toarray()\n",
    "count_vec_ingr = scipy.sparse.load_npz(\"ML2_data/recipe_text_features_countvec/train_ingr_vec.npz\").toarray()\n",
    "\n",
    "test_count_vec_name = scipy.sparse.load_npz(\"ML2_data/recipe_text_features_countvec/test_name_vec.npz\").toarray()\n",
    "test_count_vec_steps = scipy.sparse.load_npz(\"ML2_data/recipe_text_features_countvec/test_steps_vec.npz\").toarray()\n",
    "test_count_vec_ingr = scipy.sparse.load_npz(\"ML2_data/recipe_text_features_countvec/test_ingr_vec.npz\").toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2vec process\n",
    "\n",
    "doc2vec100_name = pd.read_csv(\"ML2_data/recipe_text_features_doc2vec100/train_name_doc2vec100.csv\", header = None).values\n",
    "doc2vec100_steps = pd.read_csv(\"ML2_data/recipe_text_features_doc2vec100/train_steps_doc2vec100.csv\", header = None).values\n",
    "doc2vec100_ingr = pd.read_csv(\"ML2_data/recipe_text_features_doc2vec100/train_ingr_doc2vec100.csv\", header = None).values\n",
    "\n",
    "test_doc2vec100_name = pd.read_csv(\"ML2_data/recipe_text_features_doc2vec100/test_name_doc2vec100.csv\", header = None).values\n",
    "test_doc2vec100_steps = pd.read_csv(\"ML2_data/recipe_text_features_doc2vec100/test_steps_doc2vec100.csv\", header = None).values\n",
    "test_doc2vec100_ingr = pd.read_csv(\"ML2_data/recipe_text_features_doc2vec100/test_ingr_doc2vec100.csv\", header = None).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data from recipe csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate duration label\n",
    "csv_data = pd.read_csv(\"ML2_data/recipe_train.csv\")\n",
    "test_csv_data = pd.read_csv(\"ML2_data/recipe_test.csv\")\n",
    "\n",
    "#take raw features from train dataset\n",
    "n_steps = csv_data.iloc[:,1]\n",
    "n_steps = n_steps.values\n",
    "\n",
    "n_ingr = csv_data.iloc[:,2]\n",
    "n_ingr = n_ingr.values\n",
    "\n",
    "#take raw features from test dataset\n",
    "test_n_steps = test_csv_data.iloc[:,1]\n",
    "test_n_steps = test_n_steps.values\n",
    "\n",
    "test_n_ingr = test_csv_data.iloc[:,2]\n",
    "test_n_ingr = test_n_ingr.values\n",
    "\n",
    "#take class labels from train dataset as duration_array\n",
    "duration_array = csv_data.iloc[:,-1]\n",
    "duration_array = duration_array.values\n",
    "\n",
    "n_steps_array = []\n",
    "n_ingr_array = []\n",
    "test_n_steps_array = []\n",
    "test_n_ingr_array = []\n",
    "\n",
    "for i in range(len(n_steps)):\n",
    "    n_steps_array.append([n_steps[i]])\n",
    "    n_ingr_array.append([n_ingr[i]])\n",
    "    \n",
    "for i in range(len(test_n_steps)):\n",
    "    test_n_steps_array.append([test_n_steps[i]])\n",
    "    test_n_ingr_array.append([test_n_ingr[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.hstack([n_steps_array,\n",
    "                        n_ingr_array,\n",
    "                        doc2vec100_steps,\n",
    "                        count_vec_name,\n",
    "                        count_vec_ingr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.hstack([test_n_steps_array,\n",
    "                       test_n_ingr_array,\n",
    "                       test_doc2vec100_steps,\n",
    "                       test_count_vec_name,\n",
    "                       test_count_vec_ingr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train = train_data, test_data, duration_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del count_vec_name\n",
    "del count_vec_steps\n",
    "del count_vec_ingr\n",
    "del doc2vec100_name \n",
    "del doc2vec100_steps\n",
    "del doc2vec100_ingr \n",
    "del n_steps\n",
    "del n_ingr\n",
    "del duration_array\n",
    "del n_steps_array \n",
    "del n_ingr_array\n",
    "\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select k-best features\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=1000)\n",
    "kbest.fit(X_train, y_train)\n",
    "X_train = kbest.transform(X_train)\n",
    "X_test = kbest.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:18:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import svm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import time\n",
    "\n",
    "#try different classifiers and evaluate individual model performance\n",
    "#code adapated from Practical 8\n",
    "\n",
    "models = [RandomForestClassifier(n_estimators=100),\n",
    "          LogisticRegression(),\n",
    "          GaussianNB(),\n",
    "          DecisionTreeClassifier(),\n",
    "          svm.LinearSVC(),\n",
    "          XGBClassifier(tree_method='gpu_hist')]\n",
    "\n",
    "titles = ['Random Forest',\n",
    "          'Logistic Regression',\n",
    "          'GNB',\n",
    "          'Decision Tree',\n",
    "         'Linear SVC',\n",
    "         'XGB']\n",
    "\n",
    "#add output rows to csv files for eeach model\n",
    "for title, model in zip(titles, models):\n",
    "  \n",
    "    output = []\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "  \n",
    "    for i in range(len(y_predict)):\n",
    "        row = [i+1, y_predict[i]]\n",
    "        output.append(row)\n",
    "  \n",
    "    output = pd.DataFrame(output, columns = ['id', 'duration_label'])\n",
    "    output.to_csv(title + '_CV.csv', index = False)\n",
    "\n",
    "#for model, title in zip(models, titles):\n",
    "#    \n",
    "#    t_start = time.time()\n",
    "#    model.fit(X_train, y_train)\n",
    "#    print(title, \"accuracy: \", model.score(X_test, y_test))\n",
    "#    t_end = time.time()\n",
    "#\n",
    "#    print(\"Time elapsed: \", t_end - t_start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost algo\n",
    "#t_start = time.time()\n",
    "#xgb = XGBClassifier(random_state=0, tree_method='gpu_hist').fit(X_train, y_train)\n",
    "#\n",
    "#\n",
    "#t_end = time.time()\n",
    "#print(\"Time elapsed: \", t_end - t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rf', RandomForestClassifier()), ('lr', LogisticRegression()), ('xgb', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method='gpu_hist',\n",
      "              validate_parameters=None, verbosity=None))]\n"
     ]
    }
   ],
   "source": [
    "#choose classifiers for stacking algo\n",
    "classifiers = [RandomForestClassifier(n_estimators=100),\n",
    "              LogisticRegression(),\n",
    "              XGBClassifier(tree_method='gpu_hist')]\n",
    "\n",
    "class_titles = ['rf',\n",
    "               'lr',\n",
    "               'xgb']\n",
    "\n",
    "print(list(zip(class_titles, classifiers)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:19:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:21:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:21:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:21:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:21:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Time elapsed: 190.40948700904846\n"
     ]
    }
   ],
   "source": [
    "#use stacking classifier\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "t_start = time.time()\n",
    "clf = StackingClassifier(estimators = list(zip(class_titles, classifiers)))\n",
    "clf.fit(X_train, y_train)\n",
    "t_end = time.time()\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "output = []\n",
    "\n",
    "#print stacking classifier rows to csv file\n",
    "for i in range(len(y_predict)):\n",
    "    row = [i+1, y_predict[i]]\n",
    "    output.append(row)\n",
    "print(\"Time elapsed:\", t_end-t_start)\n",
    "\n",
    "output = pd.DataFrame(output, columns = ['id', 'duration_label'])\n",
    "output.to_csv('Final' + '_Stacker.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
