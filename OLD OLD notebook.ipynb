{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2021 Semester 1\n",
    "\n",
    "## Assignment 2: Duration Classification with Recipe Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student ID(s): 1004503, 1005418"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
<<<<<<< Updated upstream
    "import pickle\n",
    "from collections import defaultdict\n",
=======
    "#import pickle\n",
    "import scipy\n",
    "#from xgboost import XGBClassifier\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
<<<<<<< HEAD:.ipynb_checkpoints/Code [FINAL]-checkpoint.ipynb
    "warnings.filterwarnings('ignore')"
=======
>>>>>>> Stashed changes
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "#testing"
>>>>>>> parent of dd77ce2 (Revert "Revert "Implemented StackClassifier, other classifiers, time evaluation""):Code1 - CountVec Pre-process.ipynb
   ]
  },
  {
<<<<<<< Updated upstream
=======
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process for count vectorizer and doc2vec"
   ]
  },
  {
>>>>>>> Stashed changes
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectoriser process\n",
    "\n",
<<<<<<< HEAD:.ipynb_checkpoints/Code [FINAL]-checkpoint.ipynb
    "count_vec_name = scipy.sparse.load_npz(\"ML2_data/recipe_text_features_countvec/train_name_vec.npz\").toarray()\n",
    "count_vec_steps = scipy.sparse.load_npz(\"ML2_data/recipe_text_features_countvec/train_steps_vec.npz\").toarray()\n",
    "count_vec_ingr = scipy.sparse.load_npz(\"ML2_data/recipe_text_features_countvec/train_ingr_vec.npz\").toarray()\n",
    "\n",
    "test_count_vec_name = scipy.sparse.load_npz(\"ML2_data/recipe_text_features_countvec/test_name_vec.npz\").toarray()\n",
    "test_count_vec_steps = scipy.sparse.load_npz(\"ML2_data/recipe_text_features_countvec/test_steps_vec.npz\").toarray()\n",
    "test_count_vec_ingr = scipy.sparse.load_npz(\"ML2_data/recipe_text_features_countvec/test_ingr_vec.npz\").toarray()\n"
=======
    "n_vocab = pickle.load(open(\"ML2_data/recipe_text_features_countvec/train_name_countvectorizer.pkl\", \"rb\"))\n",
    "n_vocab_dict = n_vocab.vocabulary_\n",
    "\n",
    "s_vocab = pickle.load(open(\"ML2_data/recipe_text_features_countvec/train_steps_countvectorizer.pkl\", \"rb\"))\n",
    "s_vocab_dict = s_vocab.vocabulary_\n",
    "\n",
    "i_vocab = pickle.load(open(\"ML2_data/recipe_text_features_countvec/train_ingr_countvectorizer.pkl\", \"rb\"))\n",
    "i_vocab_dict = i_vocab.vocabulary_\n",
    "\n",
    "train = pd.read_csv('ML2_data/recipe_train.csv')\n",
    "\n",
    "X_train_raw = train.iloc[:,:-1]\n",
    "y_train = train.iloc[:,-1]\n",
    "\n",
    "X_test_raw = pd.read_csv('ML2_data/recipe_test.csv')\n"
>>>>>>> parent of dd77ce2 (Revert "Revert "Implemented StackClassifier, other classifiers, time evaluation""):Code1 - CountVec Pre-process.ipynb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:.ipynb_checkpoints/Code [FINAL]-checkpoint.ipynb
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2vec process\n",
    "\n",
    "doc2vec100_name = pd.read_csv(\"ML2_data/recipe_text_features_doc2vec100/train_name_doc2vec100.csv\", header = None).values\n",
    "doc2vec100_steps = pd.read_csv(\"ML2_data/recipe_text_features_doc2vec100/train_steps_doc2vec100.csv\", header = None).values\n",
    "doc2vec100_ingr = pd.read_csv(\"ML2_data/recipe_text_features_doc2vec100/train_ingr_doc2vec100.csv\", header = None).values\n",
    "\n",
    "test_doc2vec100_name = pd.read_csv(\"ML2_data/recipe_text_features_doc2vec100/test_name_doc2vec100.csv\", header = None).values\n",
    "test_doc2vec100_steps = pd.read_csv(\"ML2_data/recipe_text_features_doc2vec100/test_steps_doc2vec100.csv\", header = None).values\n",
    "test_doc2vec100_ingr = pd.read_csv(\"ML2_data/recipe_text_features_doc2vec100/test_ingr_doc2vec100.csv\", header = None).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data from recipe csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate duration label\n",
    "csv_data = pd.read_csv(\"ML2_data/recipe_train.csv\")\n",
    "test_csv_data = pd.read_csv(\"ML2_data/recipe_test.csv\")\n",
    "\n",
    "#take raw features from train dataset\n",
    "n_steps = csv_data.iloc[:,1]\n",
    "n_steps = n_steps.values\n",
=======
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 38,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 3,
=======
   "execution_count": 39,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit countvec/doc2vec features onto text feature columns\n",
    "#TODO: try doc2vec as well and compare performance\n",
    "\n",
    "Xtrain_names = list(X_train_raw['name'])\n",
    "Xtrain_ingredients = list(X_train_raw['ingredients'])\n",
    "Xtrain_steps = list(X_train_raw['steps'])\n",
    "\n",
    "Xtest_names = list(X_test_raw['name'])\n",
    "Xtest_steps = list(X_test_raw['steps'])\n",
    "Xtest_ingredients = list(X_test_raw['ingredients'])\n",
>>>>>>> parent of dd77ce2 (Revert "Revert "Implemented StackClassifier, other classifiers, time evaluation""):Code1 - CountVec Pre-process.ipynb
    "\n",
    "#transforms each countvec into a dense matrix containing corresponding text features\n",
    "Xtrain_names =  n_vocab.fit_transform(Xtrain_names).todense()\n",
    "Xtest_names = n_vocab.transform(Xtest_names).todense()\n",
    "\n",
<<<<<<< HEAD:.ipynb_checkpoints/Code [FINAL]-checkpoint.ipynb
    "#take raw features from test dataset\n",
    "test_n_steps = test_csv_data.iloc[:,1]\n",
    "test_n_steps = test_n_steps.values\n",
    "\n",
    "test_n_ingr = test_csv_data.iloc[:,2]\n",
    "test_n_ingr = test_n_ingr.values\n",
    "\n",
    "#take class labels from train dataset as duration_array\n",
    "duration_array = csv_data.iloc[:,-1]\n",
    "duration_array = duration_array.values\n",
=======
<<<<<<< Updated upstream
    "Xtrain_steps =  s_vocab.fit_transform(Xtrain_steps).todense()\n",
    "Xtest_steps = s_vocab.transform(Xtest_steps).todense()\n",
>>>>>>> parent of dd77ce2 (Revert "Revert "Implemented StackClassifier, other classifiers, time evaluation""):Code1 - CountVec Pre-process.ipynb
    "\n",
    "Xtrain_ingredients =  i_vocab.fit_transform(Xtrain_ingredients).todense()\n",
    "Xtest_ingredients = i_vocab.transform(Xtest_ingredients).todense()"
=======
    "n_steps_array = []\n",
    "n_ingr_array = []\n",
    "test_n_steps_array = []\n",
    "test_n_ingr_array = []\n",
    "\n",
    "for i in range(len(n_steps)):\n",
    "    n_steps_array.append([n_steps[i]])\n",
    "    n_ingr_array.append([n_ingr[i]])\n",
    "    \n",
    "for i in range(len(test_n_steps)):\n",
    "    test_n_steps_array.append([test_n_steps[i]])\n",
    "    test_n_ingr_array.append([test_n_ingr[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD:.ipynb_checkpoints/Code [FINAL]-checkpoint.ipynb
    "train_data = np.hstack([n_steps_array,\n",
    "                        n_ingr_array,\n",
    "                        doc2vec100_steps,\n",
    "                        count_vec_name,\n",
    "                        count_vec_ingr])"
=======
    "train_data = np.hstack([n_steps_array, n_ingr_array, doc2vec100_steps, count_vec_name, count_vec_ingr])"
>>>>>>> Stashed changes
>>>>>>> parent of dd77ce2 (Revert "Revert "Implemented StackClassifier, other classifiers, time evaluation""):Code1 - CountVec Pre-process.ipynb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:.ipynb_checkpoints/Code [FINAL]-checkpoint.ipynb
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.hstack([test_n_steps_array,\n",
    "                       test_n_ingr_array,\n",
    "                       test_doc2vec100_steps,\n",
    "                       test_count_vec_name,\n",
    "                       test_count_vec_ingr])"
=======
<<<<<<< Updated upstream
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch columns with CountVec/Word2Vec fitted values\n",
    "\n",
    "Xtrain = X_train_raw\n",
    "Xtest = X_test_raw\n",
    "\n",
    "Xtrain['name'] = Xtrain_names\n",
    "Xtrain['steps'] = Xtrain_steps\n",
    "Xtrain['ingredients'] = Xtrain_ingredients\n",
    "\n",
    "Xtest['name'] = Xtest_names\n",
    "Xtest['steps'] = Xtest_steps\n",
    "Xtest['ingredients'] = Xtest_ingredients"
=======
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, duration_array, test_size=0.25, random_state=42, stratify=duration_array)"
>>>>>>> Stashed changes
>>>>>>> parent of dd77ce2 (Revert "Revert "Implemented StackClassifier, other classifiers, time evaluation""):Code1 - CountVec Pre-process.ipynb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:.ipynb_checkpoints/Code [FINAL]-checkpoint.ipynb
   "execution_count": null,
=======
<<<<<<< Updated upstream
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>steps</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  n_steps  n_ingredients  steps  ingredients\n",
       "0     0        6             12      0            0\n",
       "1     0        9              5      0            0\n",
       "2     0       15             10      0            0\n",
       "3     0       10              8      0            0\n",
       "4     0        6              5      0            0\n",
       "5     0       13             10      0            0\n",
       "6     0       10              9      0            0\n",
       "7     0       24              9      0            0\n",
       "8     0        4              8      0            0\n",
       "9     0        7              4      0            0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 11,
>>>>>>> parent of dd77ce2 (Revert "Revert "Implemented StackClassifier, other classifiers, time evaluation""):Code1 - CountVec Pre-process.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train = train_data, test_data, duration_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del count_vec_name\n",
    "del count_vec_steps\n",
    "del count_vec_ingr\n",
    "del doc2vec100_name \n",
    "del doc2vec100_steps\n",
    "del doc2vec100_ingr \n",
    "del n_steps\n",
    "del n_ingr\n",
    "del duration_array\n",
    "del n_steps_array \n",
    "del n_ingr_array\n",
    "\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select k-best features\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=1000)\n",
    "kbest.fit(X_train, y_train)\n",
    "X_train = kbest.transform(X_train)\n",
    "X_test = kbest.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< HEAD:.ipynb_checkpoints/Code [FINAL]-checkpoint.ipynb
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy:  0.7864\n",
      "Time elapsed:  21.77417540550232\n",
      "0-R accuracy:  0.5062\n",
      "Time elapsed:  0.002000093460083008\n",
      "Logistic Regression accuracy:  0.7987\n",
      "Time elapsed:  2.427544355392456\n",
      "GNB accuracy:  0.6946\n",
      "Time elapsed:  0.3120710849761963\n",
      "Decision Tree accuracy:  0.716\n",
      "Time elapsed:  8.770989656448364\n",
      "Linear SVC accuracy:  0.7989\n",
      "Time elapsed:  39.292195558547974\n"
     ]
    }
   ],
>>>>>>> Stashed changes
>>>>>>> parent of dd77ce2 (Revert "Revert "Implemented StackClassifier, other classifiers, time evaluation""):Code1 - CountVec Pre-process.ipynb
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import svm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import time\n",
    "\n",
    "#try different classifiers and evaluate individual model performance\n",
    "#code adapated from Practical 8\n",
    "\n",
    "models = [RandomForestClassifier(n_estimators=100),\n",
    "          LogisticRegression(),\n",
    "          GaussianNB(),\n",
    "          DecisionTreeClassifier(),\n",
    "          svm.LinearSVC(),\n",
    "          XGBClassifier(tree_method='gpu_hist')]\n",
    "\n",
    "titles = ['Random Forest',\n",
    "          'Logistic Regression',\n",
    "          'GNB',\n",
    "          'Decision Tree',\n",
    "         'Linear SVC',\n",
    "         'XGB']\n",
    "\n",
    "for title, model in zip(titles, models):\n",
<<<<<<< HEAD:.ipynb_checkpoints/Code [FINAL]-checkpoint.ipynb
    "  \n",
    "    output = []\n",
=======
    "    \n",
    "    output = []\n",
    "    model.fit(Xtrain, y_train)\n",
    "    y_predict = model.predict(Xtest)\n",
    "    \n",
    "    for i in range(len(y_predict)):\n",
    "        row = [i+1, y_predict[i]]\n",
    "        output.append(row)\n",
    "    \n",
    "    \n",
<<<<<<< Updated upstream
    "    output = pd.DataFrame(output, columns = ['id', 'duration_label'])\n",
    "    output.to_csv(title + '_CV.csv', index = False)\n",
    "    \n"
=======
    "#      output = pd.DataFrame(output, columns = ['id', 'duration_label'])\n",
    "#      output.to_csv(title + '_CV.csv', index = False)\n",
    "\n",
    "for model, title in zip(models, titles):\n",
    "    \n",
    "    t_start = time.time()\n",
>>>>>>> parent of dd77ce2 (Revert "Revert "Implemented StackClassifier, other classifiers, time evaluation""):Code1 - CountVec Pre-process.ipynb
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "  \n",
    "    for i in range(len(y_predict)):\n",
    "        row = [i+1, y_predict[i]]\n",
    "        output.append(row)\n",
    "  \n",
    "    output = pd.DataFrame(output, columns = ['id', 'duration_label'])\n",
    "    output.to_csv(title + '_CV.csv', index = False)\n",
    "\n",
    "#for model, title in zip(models, titles):\n",
    "#    \n",
    "#    t_start = time.time()\n",
    "#    model.fit(X_train, y_train)\n",
    "#    print(title, \"accuracy: \", model.score(X_test, y_test))\n",
    "#    t_end = time.time()\n",
    "#\n",
    "#    print(\"Time elapsed: \", t_end - t_start)\n",
    "\n"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD:.ipynb_checkpoints/Code [FINAL]-checkpoint.ipynb
=======
<<<<<<< Updated upstream
   "source": []
=======
>>>>>>> parent of dd77ce2 (Revert "Revert "Implemented StackClassifier, other classifiers, time evaluation""):Code1 - CountVec Pre-process.ipynb
   "source": [
    "#XGBoost algo\n",
    "#t_start = time.time()\n",
    "#xgb = XGBClassifier(random_state=0, tree_method='gpu_hist').fit(X_train, y_train)\n",
    "#\n",
    "#\n",
    "#t_end = time.time()\n",
    "#print(\"Time elapsed: \", t_end - t_start)"
   ]
>>>>>>> Stashed changes
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose classifiers for stacking algo\n",
    "classifiers = [RandomForestClassifier(n_estimators=100),\n",
    "              LogisticRegression(),\n",
    "              XGBClassifier(tree_method='gpu_hist')]\n",
    "\n",
    "class_titles = ['rf',\n",
    "               'lr',\n",
    "               'xgb']\n",
    "\n",
    "print(list(zip(class_titles, classifiers)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use stacking classifier\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "t_start = time.time()\n",
    "clf = StackingClassifier(estimators = list(zip(class_titles, classifiers)))\n",
    "clf.fit(X_train, y_train)\n",
    "t_end = time.time()\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "output = []\n",
    "\n",
    "for i in range(len(y_predict)):\n",
    "    row = [i+1, y_predict[i]]\n",
    "    output.append(row)\n",
    "print(\"Time elapsed:\", t_end-t_start)\n",
    "\n",
    "output = pd.DataFrame(output, columns = ['id', 'duration_label'])\n",
    "output.to_csv('Final' + '_Stacker.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print stacking classifier rows to csv file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
