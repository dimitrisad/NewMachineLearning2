{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2021 Semester 1\n",
    "\n",
    "## Assignment 2: Duration Classification with Recipe Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student ID(s): 1004503, 1005418"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
<<<<<<< Updated upstream
    "import pickle\n",
    "from collections import defaultdict\n",
=======
    "#import pickle\n",
    "import scipy\n",
    "#from xgboost import XGBClassifier\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
>>>>>>> Stashed changes
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "#testing"
   ]
  },
  {
<<<<<<< Updated upstream
=======
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process for count vectorizer and doc2vec"
   ]
  },
  {
>>>>>>> Stashed changes
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectoriser process\n",
    "\n",
    "n_vocab = pickle.load(open(\"ML2_data/recipe_text_features_countvec/train_name_countvectorizer.pkl\", \"rb\"))\n",
    "n_vocab_dict = n_vocab.vocabulary_\n",
    "\n",
    "s_vocab = pickle.load(open(\"ML2_data/recipe_text_features_countvec/train_steps_countvectorizer.pkl\", \"rb\"))\n",
    "s_vocab_dict = s_vocab.vocabulary_\n",
    "\n",
    "i_vocab = pickle.load(open(\"ML2_data/recipe_text_features_countvec/train_ingr_countvectorizer.pkl\", \"rb\"))\n",
    "i_vocab_dict = i_vocab.vocabulary_\n",
    "\n",
    "train = pd.read_csv('ML2_data/recipe_train.csv')\n",
    "\n",
    "X_train_raw = train.iloc[:,:-1]\n",
    "y_train = train.iloc[:,-1]\n",
    "\n",
    "X_test_raw = pd.read_csv('ML2_data/recipe_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 38,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 3,
=======
   "execution_count": 39,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit countvec/doc2vec features onto text feature columns\n",
    "#TODO: try doc2vec as well and compare performance\n",
    "\n",
    "Xtrain_names = list(X_train_raw['name'])\n",
    "Xtrain_ingredients = list(X_train_raw['ingredients'])\n",
    "Xtrain_steps = list(X_train_raw['steps'])\n",
    "\n",
    "Xtest_names = list(X_test_raw['name'])\n",
    "Xtest_steps = list(X_test_raw['steps'])\n",
    "Xtest_ingredients = list(X_test_raw['ingredients'])\n",
    "\n",
    "#transforms each countvec into a dense matrix containing corresponding text features\n",
    "Xtrain_names =  n_vocab.fit_transform(Xtrain_names).todense()\n",
    "Xtest_names = n_vocab.transform(Xtest_names).todense()\n",
    "\n",
<<<<<<< Updated upstream
    "Xtrain_steps =  s_vocab.fit_transform(Xtrain_steps).todense()\n",
    "Xtest_steps = s_vocab.transform(Xtest_steps).todense()\n",
    "\n",
    "Xtrain_ingredients =  i_vocab.fit_transform(Xtrain_ingredients).todense()\n",
    "Xtest_ingredients = i_vocab.transform(Xtest_ingredients).todense()"
=======
    "n_steps_array = []\n",
    "n_ingr_array = []\n",
    "for i in range(len(n_steps)):\n",
    "    n_steps_array.append([n_steps[i]])\n",
    "    n_ingr_array.append([n_ingr[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.hstack([n_steps_array, n_ingr_array, doc2vec100_steps, count_vec_name, count_vec_ingr])"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch columns with CountVec/Word2Vec fitted values\n",
    "\n",
    "Xtrain = X_train_raw\n",
    "Xtest = X_test_raw\n",
    "\n",
    "Xtrain['name'] = Xtrain_names\n",
    "Xtrain['steps'] = Xtrain_steps\n",
    "Xtrain['ingredients'] = Xtrain_ingredients\n",
    "\n",
    "Xtest['name'] = Xtest_names\n",
    "Xtest['steps'] = Xtest_steps\n",
    "Xtest['ingredients'] = Xtest_ingredients"
=======
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, duration_array, test_size=0.25, random_state=42, stratify=duration_array)"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>steps</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  n_steps  n_ingredients  steps  ingredients\n",
       "0     0        6             12      0            0\n",
       "1     0        9              5      0            0\n",
       "2     0       15             10      0            0\n",
       "3     0       10              8      0            0\n",
       "4     0        6              5      0            0\n",
       "5     0       13             10      0            0\n",
       "6     0       10              9      0            0\n",
       "7     0       24              9      0            0\n",
       "8     0        4              8      0            0\n",
       "9     0        7              4      0            0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del count_vec_name\n",
    "del count_vec_steps\n",
    "del count_vec_ingr\n",
    "del doc2vec100_name \n",
    "del doc2vec100_steps\n",
    "del doc2vec100_ingr \n",
    "del n_steps\n",
    "del n_ingr\n",
    "del duration_array\n",
    "del n_steps_array \n",
    "del n_ingr_array\n",
    "\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select k-best features\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=500)\n",
    "kbest.fit(X_train, y_train)\n",
    "X_train = kbest.transform(X_train)\n",
    "X_test = kbest.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy:  0.7864\n",
      "Time elapsed:  21.77417540550232\n",
      "0-R accuracy:  0.5062\n",
      "Time elapsed:  0.002000093460083008\n",
      "Logistic Regression accuracy:  0.7987\n",
      "Time elapsed:  2.427544355392456\n",
      "GNB accuracy:  0.6946\n",
      "Time elapsed:  0.3120710849761963\n",
      "Decision Tree accuracy:  0.716\n",
      "Time elapsed:  8.770989656448364\n",
      "Linear SVC accuracy:  0.7989\n",
      "Time elapsed:  39.292195558547974\n"
     ]
    }
   ],
>>>>>>> Stashed changes
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import svm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import time\n",
    "\n",
    "#try different classifiers and evaluate individual model performance\n",
    "#code adapated from Practical 8\n",
    "\n",
    "models = [RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "          DummyClassifier(strategy='most_frequent'),\n",
    "          LogisticRegression(random_state=42),\n",
    "          GaussianNB(),\n",
    "          DecisionTreeClassifier(random_state=42),\n",
    "          svm.LinearSVC(random_state=42)]\n",
    "\n",
    "titles = ['Random Forest',\n",
    "          '0-R',\n",
    "          'Logistic Regression',\n",
    "          'GNB',\n",
    "          'Decision Tree',\n",
    "         'Linear SVC']\n",
    "\n",
    "for title, model in zip(titles, models):\n",
    "    \n",
    "    output = []\n",
    "    model.fit(Xtrain, y_train)\n",
    "    y_predict = model.predict(Xtest)\n",
    "    \n",
    "    for i in range(len(y_predict)):\n",
    "        row = [i+1, y_predict[i]]\n",
    "        output.append(row)\n",
    "    \n",
    "    \n",
<<<<<<< Updated upstream
    "    output = pd.DataFrame(output, columns = ['id', 'duration_label'])\n",
    "    output.to_csv(title + '_CV.csv', index = False)\n",
    "    \n"
=======
    "#      output = pd.DataFrame(output, columns = ['id', 'duration_label'])\n",
    "#      output.to_csv(title + '_CV.csv', index = False)\n",
    "\n",
    "for model, title in zip(models, titles):\n",
    "    \n",
    "    t_start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    print(title, \"accuracy: \", model.score(X_test, y_test))\n",
    "    t_end = time.time()\n",
    "\n",
    "    print(\"Time elapsed: \", t_end - t_start)\n",
    "\n"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
<<<<<<< Updated upstream
   "source": []
=======
   "source": [
    "#XGBoost algo\n",
    "t_start = time.time()\n",
    "xgb = XGBClassifier(random_state=0, tree_method='gpu_hist').fit(X_train, y_train)\n",
    "print(\"XGB accuracy: \", xgb.score(X_test, y_test))\n",
    "t_end = time.time()\n",
    "print(\"Time elapsed: \", t_end - t_start)"
   ]
>>>>>>> Stashed changes
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rf', RandomForestClassifier(random_state=42)), ('lr', LogisticRegression(random_state=42)), ('svc', LinearSVC(random_state=42))]\n"
     ]
    }
   ],
   "source": [
    "#choose classifiers for stacking algo\n",
    "classifiers = [RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "          LogisticRegression(random_state=42),\n",
    "          svm.LinearSVC(random_state=42)]\n",
    "\n",
    "class_titles = ['rf',\n",
    "               'lr',\n",
    "               'svc']\n",
    "\n",
    "print(list(zip(class_titles, classifiers)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacker accuracy: 0.8018\n",
      "Time elapsed: 300.223571062088\n"
     ]
    }
   ],
   "source": [
    "#use stacking classifier\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "t_start = time.time()\n",
    "clf = StackingClassifier(estimators = list(zip(class_titles, classifiers)))\n",
    "score = clf.fit(X_train, y_train).score(X_test, y_test)\n",
    "t_end = time.time()\n",
    "\n",
    "print(\"Stacker accuracy:\", score)\n",
    "print(\"Time elapsed:\", t_end-t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
